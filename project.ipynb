{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Advanced Lane Lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Calibration\n",
    "\n",
    "The camera is calibrated using the cv2 functions on the following 20 chessboard images.\n",
    "<figure>\n",
    " <img src=\"output_images/calibration_images.jpg\" width=\"720\" alt=\"Calibration Images\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> These 20 images are used for the camera calibration. </p> \n",
    " </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def undistortAll(nx=9, ny=6):\n",
    "    objpoints = []\n",
    "    imgpoints = []\n",
    "    shape = []\n",
    "    objp = np.zeros((nx * ny, 3), np.float32)\n",
    "    objp[:, :2] = np.mgrid[0:nx, 0:ny].T.reshape(-1, 2)\n",
    "\n",
    "    # Use 20 images for calibration\n",
    "    fnames = glob.glob('camera_cal/calibration*.jpg')\n",
    "    for fname in fnames:\n",
    "        img = plt.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        shape = gray.shape[::-1]\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "        if ret:\n",
    "            cv2.drawChessboardCorners(img, (nx, ny), corners, ret)\n",
    "            imgpoints.append(corners)\n",
    "            objpoints.append(objp)\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, shape, None, None)\n",
    "    return mtx, dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img src=\"output_images/undistorted_chess.jpg\" width=\"720\" alt=\"Undistorted Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> An example of the undistorted chessboard image. </p> \n",
    " </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Transform\n",
    "The input image is transformed to a binary image by color transform and gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def thres(img, s_thresh=(170, 255), sx_thresh=(80, 130), h_thresh=(0,180)):\n",
    "    img = np.copy(img)\n",
    "    \n",
    "    # Convert to HLS color space and separate the V channel\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS).astype(np.float)\n",
    "    h_channel = hls[:,:,0]\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    \n",
    "    # Sobel x\n",
    "    sobelx = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    \n",
    "    # Threshold x gradient\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1\n",
    "    \n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "    \n",
    "    h_binary = np.zeros_like(h_channel)\n",
    "    h_binary[(h_channel >= h_thresh[0]) & (h_channel <= h_thresh[1])] = 1\n",
    "    \n",
    "    # Stack each channel\n",
    "    combined_binary = np.zeros_like(sxbinary)\n",
    "    combined_binary[(s_binary == 1) | (sxbinary == 1)] = 1\n",
    "    \n",
    "    hcombined_binary = np.zeros_like(sxbinary)\n",
    "    hcombined_binary[(h_binary == 1) & ((s_binary == 1) | (sxbinary == 1))] = 1\n",
    "\n",
    "    return hcombined_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective Transform\n",
    "The binary image is transformed to a birds-eye-view. The transform matrix is calculated from the test image with the straight lines.\n",
    "<figure>\n",
    " <img src=\"output_images/transform_straight_lines1.jpg\" width=\"320\" alt=\"Transform Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Straight lane lines used to find the perspective transformation. </p> \n",
    " </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getMat():\n",
    "    src = np.float32([[265,675], [603,444], [677,444], [1015,675]])\n",
    "    dst = np.float32([[400,720], [400,0], [880,0], [880,720]])\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    return M, Minv\n",
    "\n",
    "def transform(img, M):\n",
    "    warped = cv2.warpPerspective(img, M, img.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "    return warped\n",
    "\n",
    "def getWarped(img, mtx, dist, M):\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    binary = thres(undist)\n",
    "    warped = transform(binary, M)\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of the transforms are shown on the test images.\n",
    "<figure>\n",
    " <img src=\"output_images/test_warped_0.jpg\" width=\"1024\" alt=\"Transformed Image 1\" />\n",
    " <img src=\"output_images/test_warped_1.jpg\" width=\"1024\" alt=\"Transformed Image 2\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Left: Original input image from the camera. Middle: Color transformed binary image after thresholding. Right: Binary image after perspective transform. </p> \n",
    " </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding lane lines\n",
    "\n",
    "The lane lines are found by moving boxes around the imgage and finding the active pixels in the box.\n",
    "\n",
    "The serach begins from the bottom of the image. The initial position of the boxes are determined by the histograms. \n",
    "\n",
    "In order to reduce the noise, the histograms are weighted by the guessed x positions for left and right. By default, the guessed x values are taken from the values that are used in the perspective transform of the test image with the straight lines. If the box search is performed in the middle of the video frames, the guess values may be set to the x values from the previous frame.\n",
    "\n",
    "<figure>\n",
    " <img src=\"output_images/box_search.png\" width=\"480\" alt=\"Lane Line Box Search\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Lane lines found by box search method. </p> \n",
    " </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weightedHist(hist, guess_left=400, guess_right=880):\n",
    "    xlen = hist.shape[0]\n",
    "    midx = int(xlen / 2)\n",
    "    guess_width = guess_left / 2\n",
    "    normx = range(xlen)\n",
    "    norm_left = scipy.stats.norm.pdf(normx, guess_left, guess_width)\n",
    "    norm_left /= np.max(norm_left)\n",
    "    norm_left[midx:] = 1\n",
    "    norm_right = scipy.stats.norm.pdf(normx, guess_right, guess_width)\n",
    "    norm_right /= np.max(norm_right)\n",
    "    norm_right[:midx] = 1\n",
    "    h2 = hist * norm_right * norm_left\n",
    "    return h2\n",
    "\n",
    "def getCurves(lefty, leftx, righty, rightx, y_eval):\n",
    "    left_curverad = getCurve(lefty, leftx, y_eval)\n",
    "    right_curverad = getCurve(righty, rightx, y_eval)\n",
    "    return left_curverad, right_curverad\n",
    "\n",
    "def getCurve(y, x, y_eval):\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/480 # meters per pixel in x dimension\n",
    "\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    fit_cr = np.polyfit(y*ym_per_pix, x*xm_per_pix, 2)\n",
    "    # Calculate the new radii of curvature\n",
    "    curverad = ((1 + (2*fit_cr[0]*y_eval*ym_per_pix + fit_cr[1])**2)**1.5) / np.absolute(2*fit_cr[0])\n",
    "    # Now our radius of curvature is in meters\n",
    "    return curverad\n",
    "\n",
    "def boxSearch(warped):\n",
    "    midx = int(warped.shape[1]/2)\n",
    "    midy = int(warped.shape[0]/2)\n",
    "    \n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram0 = np.sum(warped[midy:,:], axis=0)\n",
    "    histogram = weightedHist(histogram0)\n",
    "\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((warped, warped, warped))*255\n",
    "    \n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    leftx_base = np.argmax(histogram[:midx])\n",
    "    rightx_base = np.argmax(histogram[midx:]) + midx\n",
    "\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    \n",
    "    # Set height of windows\n",
    "    window_height = np.int(warped.shape[0]/nwindows)\n",
    "    \n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "\n",
    "        # Darw the wdindows on the visualization image\n",
    "        cv2.rectangle(out_img, (win_xleft_low, win_y_low), (win_xleft_high, win_y_high), (0, 255, 0), 2)\n",
    "        cv2.rectangle(out_img, (win_xright_low, win_y_low), (win_xright_high, win_y_high), (0, 255, 0), 2)\n",
    "\n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\n",
    "            (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\n",
    "            (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "\n",
    "        # If uou found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:\n",
    "            rightx_current  = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return lefty, leftx, righty, rightx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial based search for lane lines\n",
    "Once lane lines are found in a frame, we can use the polynomial fits as the reference for the search in the next frame. Following example is a particularly hard one due to the noise from the shadows on the left. However, it finds reasonable lane lines thanks to the information from the previous fits.\n",
    "<figure>\n",
    " <img src=\"output_images/poly_search.png\" width=\"480\" alt=\"Polynomial Search\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Lane line found by polynomial search method. </p> \n",
    " </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def polySearch(warped, left_fit, right_fit):\n",
    "    nonzero = warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    margin = 100\n",
    "    left_lane_inds = (\n",
    "    (nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin)) &\n",
    "    (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
    "    right_lane_inds = (\n",
    "    (nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin))&\n",
    "    (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return lefty, leftx, righty, rightx\n",
    "\n",
    "def plotLines(img, warped, mtx, dist, Minv, leftLine, rightLine):\n",
    "    xm_per_pix = 3.7/480 # meters per pixel in x dimension\n",
    "    \n",
    "    ploty = np.linspace(0, warped.shape[0]-1, warped.shape[0])\n",
    "    left_fitx = leftLine.avgPlotx\n",
    "    right_fitx = rightLine.avgPlotx\n",
    "\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (img.shape[1], img.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "    \n",
    "    # Print the curvature radius.\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    locRad = (50, 50)\n",
    "    locAvg = (50, 100)\n",
    "    fontScale = 1\n",
    "    fontColor = (255, 255, 255)\n",
    "    lineType = 2\n",
    "    leftx = leftLine.getX()\n",
    "    rightx = rightLine.getX()\n",
    "    offcenter = xm_per_pix * ((leftx + rightx)/2. - warped.shape[1]/2.)\n",
    "    lr = None\n",
    "    if offcenter > 0.:\n",
    "        lr = 'Left'\n",
    "    else:\n",
    "        lr = 'Right'\n",
    "    \n",
    "    curverad = (leftLine.getAvgCurverad() + rightLine.getAvgCurverad()) / 2.\n",
    "    \n",
    "    txt = 'Radius of Curvature = {:5d}m'.format(int(curverad))\n",
    "    cv2.putText(result, txt, locRad, font, fontScale, fontColor, lineType)\n",
    "    txtAvg = 'Vehicle is {:.2f}m {} of center'.format(abs(offcenter), lr)\n",
    "    cv2.putText(result, txtAvg, locAvg, font, fontScale, fontColor, lineType)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Video\n",
    "\n",
    "The above functions are used to find the lane lines in the video file project_video.mp4.\n",
    "\n",
    "A class `Line` is defined to store the fit results and its history. An exponential moving average is used for its efficiency in calculation and memory usage. The weight `w` is a smoothing constant, or forgetting factor, taking a value between 0 and 1.\n",
    "\n",
    "For the image processing, a callable class `ProcImg` is used instead of a function. This makes it easier to store a history of previous lanes within the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mtx, dist = undistortAll()\n",
    "M, Minv = getMat()\n",
    "\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "class Line:\n",
    "    w = 0.5\n",
    "    pixely = None\n",
    "    pixelx = None\n",
    "    avgPlotx = None\n",
    "    #polynomial coefficients for the most recent fit\n",
    "    fit = None\n",
    "    curverad = None\n",
    "    #polynomial coefficients averaged over the last iterations\n",
    "    best_fit = None\n",
    "    def __init__(self, pixely, pixelx, shape):\n",
    "        # y-dim of the image\n",
    "        self.ymax = shape[1]\n",
    "        # x-dim of the image\n",
    "        self.xmax = shape[0]\n",
    "        self.ploty = np.linspace(0, shape[0]-1, shape[0])\n",
    "        self.addNewPixels(pixely, pixelx)\n",
    "        \n",
    "    def getX(self):\n",
    "        return self.avgPlotx[-1]\n",
    "    \n",
    "    def getSlope(self, y_eval):\n",
    "        return 2*self.fit[0]*y_eval + self.fit[1]\n",
    "    \n",
    "    def getSlopes(self):\n",
    "        return np.array([self.getSlope(0), self.getSlope(self.ymax/2), self.getSlope(self.ymax)])\n",
    "        \n",
    "    def addNewPixels(self, pixely, pixelx):\n",
    "        self.pixely = pixely\n",
    "        self.pixelx = pixelx\n",
    "        self.fit = np.polyfit(pixely, pixelx, 2)\n",
    "        self.curverad = getCurve(self.pixely, self.pixelx, self.ymax)\n",
    "        \n",
    "    def isGoodCurve(self):\n",
    "        return self.curverad > 150\n",
    "        \n",
    "    def isGoodFit(self):\n",
    "        return self.isGoodCurve()\n",
    "    \n",
    "    def getAvg(self, avg, newVal):\n",
    "        newAvg = self.w*newVal + (1 - self.w)*avg\n",
    "        return newAvg\n",
    "    \n",
    "    def updateAvgs(self):\n",
    "        if self.isGoodFit():\n",
    "            if self.best_fit is None:\n",
    "                self.best_fit = self.fit\n",
    "                plotx = self.fit[0]*self.ploty**2 + self.fit[1]*self.ploty + self.fit[2]\n",
    "                self.avgPlotx = plotx\n",
    "                self.avgCurverad = self.curverad\n",
    "            else:\n",
    "                plotx = self.fit[0]*self.ploty**2 + self.fit[1]*self.ploty + self.fit[2]\n",
    "                self.avgPlotx = self.getAvg(self.avgPlotx, plotx)\n",
    "                self.best_fit = np.polyfit(self.ploty, self.avgPlotx, 2)\n",
    "                \n",
    "                self.avgCurverad = self.getAvg(self.avgCurverad, self.curverad)\n",
    "                \n",
    "    def getCurverad(self):\n",
    "        return self.curverad\n",
    "    \n",
    "    def getAvgCurverad(self):\n",
    "        return getCurve(self.ploty, self.avgPlotx, self.ymax)\n",
    "\n",
    "class ProcImg:\n",
    "    def __init__(self):\n",
    "        self.leftLine = None\n",
    "        self.rightLine = None\n",
    "        self.warped = None\n",
    "    \n",
    "    def doFirstSearch(self):\n",
    "        lefty, leftx, righty, rightx = boxSearch(self.warped)\n",
    "        self.leftLine = Line(lefty, leftx, self.warped.shape)\n",
    "        self.rightLine = Line(righty, rightx, self.warped.shape)\n",
    "    def doBoxSearch(self):\n",
    "        lefty, leftx, righty, rightx = boxSearch(self.warped)\n",
    "        self.leftLine.addNewPixels(lefty, leftx)\n",
    "        self.rightLine.addNewPixels(righty, rightx)\n",
    "    def doPolySearch(self):\n",
    "        lefty, leftx, righty, rightx = polySearch(self.warped, \\\n",
    "                    self.leftLine.best_fit, self.rightLine.fit)\n",
    "        self.leftLine.addNewPixels(lefty, leftx)\n",
    "        self.rightLine.addNewPixels(righty, rightx)\n",
    "        \n",
    "    def goodAngle(self, left_slope, right_slope):\n",
    "        left_angle = np.arctan(left_slope)\n",
    "        right_angle = np.arctan(right_slope)\n",
    "        diff_angle = np.absolute(left_angle - right_angle)\n",
    "        max_angle = np.array([0.1, 0.2, 0.3])\n",
    "        return all(diff_angle < max_angle)\n",
    "        \n",
    "    def linesCompatible(self):\n",
    "        if self.leftLine is None or self.rightLine is None:\n",
    "            return True\n",
    "        left_slopes = self.leftLine.getSlopes()\n",
    "        right_slopes = self.rightLine.getSlopes()\n",
    "        return self.goodAngle(left_slopes, right_slopes)\n",
    "\n",
    "    def __call__(self, img):\n",
    "        self.warped = getWarped(img, mtx, dist, M)\n",
    "        result = img\n",
    "    \n",
    "        if self.leftLine is None:\n",
    "            self.doFirstSearch()\n",
    "            self.leftLine.updateAvgs()\n",
    "            self.rightLine.updateAvgs()\n",
    "        else:\n",
    "            self.doPolySearch()\n",
    "            if not (self.linesCompatible() and self.leftLine.isGoodFit() and self.rightLine.isGoodFit()):\n",
    "                self.doBoxSearch()\n",
    "                \n",
    "            if self.linesCompatible():\n",
    "                self.leftLine.updateAvgs()\n",
    "                self.rightLine.updateAvgs()\n",
    "            \n",
    "        if self.leftLine.best_fit is not None and self.rightLine.best_fit is not None:\n",
    "            result = plotLines(img, self.warped, mtx, dist, Minv,\n",
    "                          self.leftLine, self.rightLine)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video output_images/project.mp4\n",
      "[MoviePy] Writing video output_images/project.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [04:06<00:00,  5.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: output_images/project.mp4 \n",
      "\n",
      "CPU times: user 5min 22s, sys: 16.7 s, total: 5min 39s\n",
      "Wall time: 4min 7s\n"
     ]
    }
   ],
   "source": [
    "pimg = ProcImg()\n",
    "project_output = 'output_images/project.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "project_clip = clip1.fl_image(pimg)\n",
    "%time project_clip.write_videofile(project_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"output_images/project.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(project_output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
